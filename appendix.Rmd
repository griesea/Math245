---
title: "Final Project Appendix"
author: "Alex G. and Max M."
date: "5/31/2017"
output: pdf_document
---

```{r}
library(car)
library(lattice)
econ <- read.csv("https://raw.githubusercontent.com/griesea/Math245/master/finaldata.csv", header = TRUE, sep = ",")
#Creating ratio of imports to exports
econ$TradeRatio <- econ$Imports/econ$Exports
econ
```

##Performing EDA:

```{r}
scatterplotMatrix(~ GDP_Rate + Inflation + IntRate + PrimEducRate +SecEducRate + TerEducRate, data = econ)
scatterplotMatrix(~ GDP_Rate + MCapRate+ Population + TradeRatio + Unemployment + S.P500 + Poverty, data = econ)
```

We see that some of our variables (specifically MCapRate and Population) appear to be highly colinear (we will deal with this later).

###Transformations

We dont appear to need a tranformation to IntRate (no convincing trend appears).

```{r,fig.height=4}
plot(GDP_Rate ~ (IntRate) , data = econ)
```

Inflation looks like it needs a transformation. However, economic theory suggests a peak benefit inflation rate (with too low or too high inflation rates being detrimental to the economy). As such, we will try to make inflation a quadratic term in the model, and so do not transform it here.
```{r,fig.height=4}
plot(GDP_Rate ~ (Inflation) , data = econ)
```



From the matrix above, it appears that MCapRate might both be curved. We examine this trend further, below. There looks to be a parabolic relationship between GDP_Rate and MCapRate. To determine if this is the correct transformation, we must fit a linear model and look at the residuals. \textit{To be done after other transformations.}

```{r,fig.height=4}
plot(GDP_Rate ~ MCapRate , data = econ)
```

Next, we check if there is a transformation needed for the population explanatory variable. There does not seem any clear indication that there needs to be a transformation based on the below plot.

```{r,fig.height=4}
plot(GDP_Rate ~ Population , data = econ)
```

Next, we check if there is a transformation needed for the primary education explanatory variable. There is some clustering we would like to get rid of. However, no transformation seems to make the relationship between GDP_Rate and PrimEducRate any better.

```{r,fig.height=4}
par(mfrow=c(1,2))
plot(GDP_Rate ~ PrimEducRate , data = econ)
plot(GDP_Rate ~ sqrt(PrimEducRate) , data = econ)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
plot(GDP_Rate ~ PrimEducRate , data = econ)
plot(GDP_Rate ~ log(I(PrimEducRate/100)) , data = econ)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
plot(GDP_Rate ~ PrimEducRate , data = econ)
plot(GDP_Rate ~ I(1/(PrimEducRate)) , data = econ)
par(mfrow=c(1,1))
```

Next, we check if there is a transformation needed for the secondary education explanatory variable. There is some clustering we would like to get rid of. However, no transformations seem to improve the fit.

```{r,fig.height=4}
par(mfrow=c(1,2))
plot(GDP_Rate ~ SecEducRate , data = econ)
plot(GDP_Rate ~ log(SecEducRate) , data = econ)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
plot(GDP_Rate ~ SecEducRate , data = econ)
plot(GDP_Rate ~ I(1/(SecEducRate)) , data = econ)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
plot(GDP_Rate ~ SecEducRate , data = econ)
plot(GDP_Rate ~ sqrt(SecEducRate) , data = econ)
par(mfrow=c(1,1))
```

Finally, we check if there is a transformation needed for the tertiary education explanatory variable. There is some clustering we would like to get rid of. However, no transformations seem to improve the fit.

```{r,fig.height=4}
par(mfrow=c(1,2))
plot(GDP_Rate ~ TerEducRate , data = econ)
plot(GDP_Rate ~ log(TerEducRate) , data = econ)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
plot(GDP_Rate ~ TerEducRate , data = econ)
plot(GDP_Rate ~ I(1/(TerEducRate)) , data = econ)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
plot(GDP_Rate ~ TerEducRate , data = econ)
plot(GDP_Rate ~ sqrt(TerEducRate) , data = econ)
par(mfrow=c(1,1))
```


Trade ratio, poverty rate, and unemployment show no convincing needs for transformations:
```{r, fig.height = 4}
par(mfrow=c(1,3))
plot(GDP_Rate ~ (TradeRatio), data=econ)
plot(GDP_Rate ~ Unemployment, data=econ)
plot(GDP_Rate ~ Poverty, data=econ)
par(mfrow=c(1,1))
```

However, S.P500 might have a quadratic effect on GDP_Rate. We will test this as we fit our model. 
```{r}
plot(GDP_Rate ~ (S.P500) , data = econ)
```


###Preliminary Linear Model

Fitting only linear terms:
```{r}
test.lm1 <- lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate +SecEducRate + TerEducRate + MCapRate+ Population + TradeRatio + Unemployment + S.P500 + Poverty +President + Senate + House, data = econ)
summary(test.lm1)
```


### Checking Residual Plots

First, we check the residual plot of our linear model against inflation. From before, using economic theory we would expect there to be a parabolic relationship. However, transforming inflation does not improve the fit and we proceed with the original model.
```{r,fig.height=4}
testTrans.lm <- lm(GDP_Rate ~ I(Inflation^2)+Inflation + IntRate + PrimEducRate +SecEducRate + TerEducRate + MCapRate+ Population + TradeRatio + Unemployment + S.P500 + Poverty +President + Senate + House, data = econ)
summary(testTrans.lm)
par(mfrow=c(1,2))
plot(resid(test.lm1) ~ Inflation , data = econ)
abline(h=0)
plot(resid(testTrans.lm) ~ Inflation, data = econ)
abline(h=0)
par(mfrow=c(1,1))
```

Next, we check the residual plot of our linear model against MCapRate. We noticed a parabolic relationship previously and check for this. However, on the basis of the residual plot this seems to not improve the model significantly. As such, we check for a log transformation instead. However, this does not improve the fit and we move forward with no transformation.
```{r,fig.height=4}
testTrans.lm <- lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate + SecEducRate + TerEducRate +log(MCapRate)+ Population + TradeRatio + Unemployment + S.P500 + Poverty +President + Senate + House, data = econ)
testTrans1.lm <- lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate + SecEducRate + TerEducRate +I(MCapRate^2)+ Population + TradeRatio + Unemployment + S.P500 + Poverty +President + Senate + House, data = econ)
summary(testTrans.lm)
par(mfrow=c(1,3))
plot(resid(test.lm1) ~ MCapRate, data = econ)
abline(h=0)
plot(resid(testTrans.lm) ~ MCapRate, data = econ)
abline(h=0)
plot(resid(testTrans1.lm) ~ log(MCapRate), data = econ)
abline(h=0)
par(mfrow=c(1,1))
```

Next, we check the residual plot of our linear model against S.P500. We noted a potential parabolic relationship previously, as such we check the residual plot. On the basis of the residual plot, a parabolic transformation seems inappropriate. However, there may be a need for a log transformation. This is wildly inappropriate and we move forward with no transformation.
```{r,fig.height=4}
testTrans.lm <- lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate + SecEducRate + TerEducRate +MCapRate+ Population + TradeRatio + Unemployment + log(I(S.P500+.37))+ Poverty +President + Senate + House, data = econ)
testTrans1.lm <- lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate + SecEducRate + TerEducRate +MCapRate+ Population + TradeRatio + Unemployment + I(S.P500^2) + Poverty +President + Senate + House, data = econ)
par(mfrow=c(1,3))
plot(resid(test.lm1) ~ S.P500, data = econ)
abline(h=0)
plot(resid(testTrans.lm) ~ S.P500, data = econ)
abline(h=0)
plot(resid(testTrans1.lm) ~ log(I(S.P500+.37)), data = econ)
abline(h=0)
par(mfrow=c(1,1))
```

Next, we check the residual plot of our linear model against IntRate, PrimEducRate, SecEducRate and TerEducRate. There does not seem to be any obvious transformations that will improve the fit.
```{r,fig.height=4}
par(mfrow=c(1,4))
plot(resid(test.lm1) ~ (PrimEducRate) , data = econ)
abline(h=0)
plot(resid(test.lm1) ~ (SecEducRate) , data = econ)
abline(h=0)
plot(resid(test.lm1) ~ (TerEducRate) , data = econ)
abline(h=0)
plot(resid(test.lm1) ~ (IntRate) , data = econ)
abline(h=0)
par(mfrow=c(1,1))
```

Next, we check the residual plot of our linear model against Population, Poverty, TradeRatio and Unemployment. As expected, we conclude there is no transformation to be performed.
```{r,fig.height=4}
par(mfrow=c(1,4))
plot(resid(test.lm1) ~ Population, data = econ)
abline(h=0)
plot(resid(test.lm1) ~ TradeRatio, data = econ)
abline(h=0)
plot(resid(test.lm1) ~ Unemployment, data = econ)
abline(h=0)
plot(resid(test.lm1) ~ Poverty, data = econ)
abline(h=0)
par(mfrow=c(1,1))
```

Finally, we check for a log-linear model. However, clearly the fit is not improved.
```{r,fig.height=4}
testTrans.lm <- lm(I(1/GDP_Rate) ~ Inflation + IntRate + PrimEducRate + SecEducRate + TerEducRate +MCapRate+ Population + TradeRatio + Unemployment + Poverty +President + Senate + House, data = econ)
par(mfrow=c(1,3))
plot(resid(test.lm1) ~ fitted(test.lm1), data = econ)
abline(h=0)
plot(resid(testTrans.lm) ~ fitted(testTrans.lm), data = econ)
abline(h=0)
par(mfrow=c(1,1))
```




###Case Influence Stats

Now we check for case influence stats. We notice that case 6, which is the year 1980 is exerting large influence on our model as it has a Cook's distance of 1.5. As such, we remove the point from our data set.
```{r, fig.height=4}
cooks.distance(test.lm1)
plot(test.lm1,which=5)
plot(test.lm1,which=4)
econ1<-econ[-6,]
```

Cases 5 and 8 (years) have large Cook's distances but leverage less than 2*p/n. However, case 8 does have a student residual close to -3, as well. However, since they both do not have a Cook's distance greater than 1 and residuals less than $\pm 2$ we include both cases.
```{r, fig.height=4}
econ.lm <- lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate +SecEducRate + TerEducRate + MCapRate+ Population + TradeRatio + Unemployment + S.P500 + Poverty +President + Senate + House, data = econ1)
summary(econ.lm)
cooks.distance(econ.lm)
2*15/35
hatvalues(econ.lm)
par(mfrow=c(1,3))
plot(econ.lm,which=5)
plot(econ.lm,which=4)
plot(resid(econ.lm) ~ fitted(econ.lm))
par(mfrow=c(1,1))
```



###Assumptions

Before we can proceed with backwards selection, we must check the assumptions of our model. The QQ plot has some skewedness in both tails. However, the distribution of the residuals seems to be pretty normal. There is a small amount of left skewedness but it is not too bad. However, it seems there may be autocorrelation, as residuals closer together seem more alike than those farther apart (especially after say 1995). Also, on the basis of a Durbin Watson test, we conclude that there is no postive or negative autocorrleation at a 5\% level of significance due to a p-value of 0.578. Based on all this info, we conclude the model assumptions are more or less met.

```{r, fig.height = 4}
par(mfrow=c(1,3))
plot(econ.lm, which=1)
hist(resid(econ.lm))
qqnorm(resid(econ.lm))
qqline(resid(econ.lm))
par(mfrow=c(1,1))
plot(resid(econ.lm)~YEAR, data=econ1)
abline(h=0)
durbinWatsonTest(econ.lm)
```


###Backwards Selection

Not surprisingly, we notice that our categorical political categorical variables are insignificant. Due to the presence of some collinearity, we conduct an ANOVA F test on all three to determine if any are worth including in our model. With a p-value of .5791, we fail to reject the null hypothesis that the reduced model is adequate at a 5\% level of significance. As such, we exclude all the political categorical variables.

```{r}
summary(econ.lm)
vif(econ.lm)
econ1.lm<-lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate +SecEducRate + TerEducRate + MCapRate+ Population + TradeRatio + Unemployment + S.P500 + Poverty, data = econ1)
anova(econ1.lm,econ.lm)
```

We know that high collinearity suggests that the standard errors for coefficients may be larger than usual. Thus, the high VIF value (>5) for SecEducRate may explain its insignificance. Despite all the very large VIF values, every coefficient/explanatory variable is otherwise significant. The standard errors are also relatively small despite the high levels of collinearity. To check for the significance of SecEducRate, we theorize that only PrimEducRate siginificantly impacts GDP. However, the ANOVA F-test shows that this theory is very wrong, as the p-value of excluding both TerEducRate and SecEducRate is .00159. Thus, we reject the null hypothesis at a 5\% level of significance that the reduced model is adequate. With no theoretical reason to remove SecEducRate, we seek to include it in our model despite the high t-statistic of 3.812. We attribute this high t-statistic value to the corresponding high VIF value. Thus, this is our final model.

```{r}
summary(econ1.lm)
vif(econ1.lm)
econ2.lm<-lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate + MCapRate+ Population + TradeRatio + Unemployment + S.P500 + Poverty, data = econ1)
anova(econ1.lm,econ2.lm)
```

###Case Influence Stats

Due to a studentized residual of about -2 and a Cook's distance of nearly 1, we exclude case 5 or the year 1979 from the data set and refit. There are no other significant cases and we move forward this data set and model. Additionally, with the exclusion of this data point we now find SecEducRate is significant.
```{r, fig.height=4}
plot(econ1.lm,which=5)
cooks.distance(econ1.lm)
econ2<-econ1[-5,]
econ1.lm<-lm(GDP_Rate ~ Inflation + IntRate + PrimEducRate +SecEducRate + TerEducRate + MCapRate+ Population + TradeRatio + Unemployment + S.P500 + Poverty, data = econ2)
plot(econ1.lm,which=5)
summary(econ1.lm)
```



### Assumptions
The distribution of the residuals does seem to be relatively normal. After removing the insiginificant terms and influential cases, normality seems to be violated on the basis of the qqplot. On the basis of the residual plot, normality and constant variance seems to be satisfied. Finally, the Durbin Watson test confirms that there is no autocorrelation.

```{r, fig.height = 4}
par(mfrow=c(1,3))
plot(econ1.lm, which=1)
hist(resid(econ1.lm))
qqnorm(resid(econ1.lm))
qqline(resid(econ1.lm))
par(mfrow=c(1,1))
plot(resid(econ1.lm)~YEAR, data=econ2)
abline(h=0)
durbinWatsonTest(econ1.lm)
```


### Final model

After removing the influential cases, we have found our final model.
```{r}
summary(econ1.lm)
```


### Tables and Graphs for Paper

```{r}
par(mfrow=c(1,3))
plot(econ1.lm, which=1)
qqnorm(resid(econ1.lm))
qqline(resid(econ1.lm))
plot(resid(econ1.lm)~YEAR, data=econ2, ylab="Residuals for Linear Model", main="Residuals against Year")
abline(h=0)
par(mfrow=c(1,1))
library(stargazer)
stargazer(econ1.lm,single.row=TRUE)
plot(econ1.lm, which=5)
```



